{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkr3JWMxk9u2"
      },
      "source": [
        "# Cleaning Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 457,
      "metadata": {
        "id": "rOKk6gw2-Kbw"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy\n",
        "import pandas\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsPWakpbkXBn"
      },
      "source": [
        "### Clean training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 458,
      "metadata": {
        "id": "1b4oVA_kY7bn"
      },
      "outputs": [],
      "source": [
        "train_path = str(\"train_dirty.txt\")\n",
        "train_clean_path = str(\"test_dirty.csv\")\n",
        "\n",
        "dirty_lines = []\n",
        "clean_lines = []\n",
        "\n",
        "with open(train_path) as file:\n",
        "    for line in file.readlines():\n",
        "        line = re.sub(r\"  +\", '', line)\n",
        "        line = re.sub(r\"[\\n\\t]*\", '', line)\n",
        "        dirty_lines.append(line)\n",
        "        line = line.replace(\"\\\"\", \"\\'\")\n",
        "        line = line.replace(\"<Pros>\", \"\\\"\")\n",
        "        line = line.replace(\"<Cons>\", \"\\\"\")\n",
        "        line = line.replace(\"</Pros>\", \"\\\",1\")\n",
        "        line = line.replace(\"</Cons>\", \"\\\",0\")\n",
        "        clean_lines.append(line)\n",
        "\n",
        "with open(train_clean_path, 'w') as file:\n",
        "    for line in clean_lines:\n",
        "        file.write(line + '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preview Line Changes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 459,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<Pros>Fast, sharp printing! Toner keeps going and going...easy to setup/use - attachments available</Pros>\n",
            " => \"Fast, sharp printing! Toner keeps going and going...easy to setup/use - attachments available\",1\n",
            "\n",
            "<Pros>Inexpensive, plenty of features for the money, good sound quality.</Pros>\n",
            " => \"Inexpensive, plenty of features for the money, good sound quality.\",1\n",
            "\n",
            "<Pros>Moveable display</Pros>\n",
            " => \"Moveable display\",1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for index in random.sample(range(len(clean_lines)), 3):\n",
        "    print(dirty_lines[index])\n",
        "    print(f\" => {clean_lines[index]}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bh36uIRSkapY"
      },
      "source": [
        "### Clean prediction data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 460,
      "metadata": {
        "id": "ou8JGI6xYHTS"
      },
      "outputs": [],
      "source": [
        "predict_path = str(\"predict_dirty.txt\")\n",
        "predict_clean_path = str(\"predict_clean.csv\")\n",
        "\n",
        "dirty_lines = []\n",
        "clean_lines = []\n",
        "\n",
        "with open(predict_path, encoding='ISO-8859-1') as file:\n",
        "    for line in file.readlines():\n",
        "        line = re.sub(r\"  +\", '', line)\n",
        "        line = re.sub(r\"[\\n\\t]*\", '', line)\n",
        "        dirty_lines.append(line)\n",
        "        line = line.replace(\"\\\"\", \"\\'\")\n",
        "        line = line.replace(\"<Labs>\", \"\\\"\")\n",
        "        line = line.replace(\"</Labs>\", \"\\\",?\")\n",
        "        clean_lines.append(line)\n",
        "        # print(line)\n",
        "\n",
        "with open(predict_clean_path, 'w') as file:\n",
        "    for line in clean_lines:\n",
        "        file.write(line + '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preview Line Changes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 461,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<Labs>Durability(trust me-I have a 2 yr old), Clarity, portability, fast charging time.</Labs>\n",
            " => \"Durability(trust me-I have a 2 yr old), Clarity, portability, fast charging time.\",?\n",
            "\n",
            "<Labs>Small, great sound quality, long battery life</Labs>\n",
            " => \"Small, great sound quality, long battery life\",?\n",
            "\n",
            "<Labs>Great buy for the features and picture quality!</Labs>\n",
            " => \"Great buy for the features and picture quality!\",?\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for index in random.sample(range(len(clean_lines)), 3):\n",
        "    print(dirty_lines[index])\n",
        "    print(f\" => {clean_lines[index]}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URj_ywt5kdsQ"
      },
      "source": [
        "# Split Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Split into Train, Validation, and Predict Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 462,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kos8AOMCa7Bi",
        "outputId": "c6ea1abf-e1b5-494b-920c-1b0a17fd1a6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train & Validation\n",
            "(1299, 2)\n",
            "(700, 2)\n",
            "Predictions\n",
            "(43874, 2)\n"
          ]
        }
      ],
      "source": [
        "validation_split = 0.65\n",
        "\n",
        "predictData = pandas.read_csv(predict_clean_path, encoding='unicode_escape')\n",
        "predictData.columns = [\"Text\", \"Pro/Con\"]\n",
        "\n",
        "inputData = pandas.read_csv(train_clean_path, encoding='unicode_escape')\n",
        "inputData.columns = [\"Text\", \"Pro/Con\"]\n",
        "\n",
        "trainData = inputData.sample(frac=validation_split)\n",
        "validationData = inputData.drop(trainData.index)\n",
        "\n",
        "print(\"Train & Validation\")\n",
        "print(trainData.shape)\n",
        "print(validationData.shape)\n",
        "print(\"Predictions\")\n",
        "print(predictData.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Separate Text & Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 463,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_text = inputData['Text'].values.astype(str)\n",
        "train_label = inputData['Pro/Con'].values.astype(int)\n",
        "\n",
        "validation_text = validationData['Text'].values.astype(str)\n",
        "validation_label = validationData['Pro/Con'].values.astype(int)\n",
        "\n",
        "predict_text = predictData['Text'].values.astype(str)\n",
        "predict_label = predictData['Pro/Con'].values.astype(str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBLWDi7GrqrM"
      },
      "source": [
        "# Tokenize Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEb15xfntF0B"
      },
      "source": [
        "### w/ Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 464,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.preprocessing as tfpp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 465,
      "metadata": {
        "id": "AHcEVJt-15ho"
      },
      "outputs": [],
      "source": [
        "vocab_size = 1024\n",
        "sequence_length = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 466,
      "metadata": {
        "id": "GclqT_m32N9e"
      },
      "outputs": [],
      "source": [
        "tokenizer = tfpp.text.Tokenizer(\n",
        "    num_words=vocab_size,\n",
        "    oov_token='~misc~',\n",
        ")\n",
        "tokenizer.fit_on_texts(train_text)\n",
        "\n",
        "train_sequences = tokenizer.texts_to_sequences(train_text)\n",
        "train_padded = tfpp.sequence.pad_sequences(train_sequences, maxlen=sequence_length, truncating='post')\n",
        "\n",
        "validation_sequences = tokenizer.texts_to_sequences(validation_text)\n",
        "validation_padded = tfpp.sequence.pad_sequences(validation_sequences, maxlen=sequence_length, truncating='post')\n",
        "\n",
        "predict_sequences = tokenizer.texts_to_sequences(predict_text)\n",
        "predict_padded = tfpp.sequence.pad_sequences(predict_sequences, maxlen=sequence_length, truncating='post')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Learning Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 467,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_epochs = 250\n",
        "embedding_dim = 16\n",
        "learning_rate = 8.5e-5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Architecture & Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 468,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHGC-XdEtR2L",
        "outputId": "3db7fb5c-4f20-4861-a234-237d7bbb2b6b"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=sequence_length),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16)),\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
        "    metrics=[tf.metrics.BinaryAccuracy(name=\"accuracy\")],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 469,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "id": "oAh32Bo4t2Rm",
        "outputId": "8a256c2a-ace7-4fba-e98e-66ceef831b79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "125/125 [==============================] - 14s 51ms/step - loss: 0.6930 - accuracy: 0.4907 - val_loss: 0.6923 - val_accuracy: 0.4986\n",
            "Epoch 2/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.6917 - accuracy: 0.4972 - val_loss: 0.6903 - val_accuracy: 0.5043\n",
            "Epoch 3/250\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.6876 - accuracy: 0.5598 - val_loss: 0.6832 - val_accuracy: 0.5371\n",
            "Epoch 4/250\n",
            "125/125 [==============================] - 5s 37ms/step - loss: 0.6761 - accuracy: 0.5668 - val_loss: 0.6648 - val_accuracy: 0.6214\n",
            "Epoch 5/250\n",
            "125/125 [==============================] - 5s 37ms/step - loss: 0.6453 - accuracy: 0.6468 - val_loss: 0.6166 - val_accuracy: 0.6643\n",
            "Epoch 6/250\n",
            "125/125 [==============================] - 5s 38ms/step - loss: 0.5812 - accuracy: 0.7114 - val_loss: 0.5418 - val_accuracy: 0.8743\n",
            "Epoch 7/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.5149 - accuracy: 0.8099 - val_loss: 0.4827 - val_accuracy: 0.8943\n",
            "Epoch 8/250\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.4645 - accuracy: 0.8749 - val_loss: 0.4300 - val_accuracy: 0.9200\n",
            "Epoch 9/250\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.4101 - accuracy: 0.9025 - val_loss: 0.3735 - val_accuracy: 0.9229\n",
            "Epoch 10/250\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.3594 - accuracy: 0.9210 - val_loss: 0.3474 - val_accuracy: 0.8900\n",
            "Epoch 11/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.3134 - accuracy: 0.9255 - val_loss: 0.2806 - val_accuracy: 0.9414\n",
            "Epoch 12/250\n",
            "125/125 [==============================] - 5s 37ms/step - loss: 0.2790 - accuracy: 0.9285 - val_loss: 0.2996 - val_accuracy: 0.8986\n",
            "Epoch 13/250\n",
            "125/125 [==============================] - 5s 37ms/step - loss: 0.2519 - accuracy: 0.9330 - val_loss: 0.2273 - val_accuracy: 0.9443\n",
            "Epoch 14/250\n",
            "125/125 [==============================] - 5s 37ms/step - loss: 0.2301 - accuracy: 0.9370 - val_loss: 0.2074 - val_accuracy: 0.9471\n",
            "Epoch 15/250\n",
            "125/125 [==============================] - 5s 38ms/step - loss: 0.2094 - accuracy: 0.9475 - val_loss: 0.1877 - val_accuracy: 0.9614\n",
            "Epoch 16/250\n",
            "125/125 [==============================] - 5s 38ms/step - loss: 0.1978 - accuracy: 0.9425 - val_loss: 0.1757 - val_accuracy: 0.9614\n",
            "Epoch 17/250\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.1864 - accuracy: 0.9435 - val_loss: 0.1656 - val_accuracy: 0.9643\n",
            "Epoch 18/250\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.1711 - accuracy: 0.9530 - val_loss: 0.1535 - val_accuracy: 0.9657\n",
            "Epoch 19/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.1650 - accuracy: 0.9520 - val_loss: 0.1451 - val_accuracy: 0.9657\n",
            "Epoch 20/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.1577 - accuracy: 0.9545 - val_loss: 0.1384 - val_accuracy: 0.9686\n",
            "Epoch 21/250\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.1506 - accuracy: 0.9550 - val_loss: 0.1312 - val_accuracy: 0.9686\n",
            "Epoch 22/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.1442 - accuracy: 0.9570 - val_loss: 0.1412 - val_accuracy: 0.9571\n",
            "Epoch 23/250\n",
            "125/125 [==============================] - 5s 38ms/step - loss: 0.1401 - accuracy: 0.9570 - val_loss: 0.1261 - val_accuracy: 0.9714\n",
            "Epoch 24/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.1319 - accuracy: 0.9605 - val_loss: 0.1171 - val_accuracy: 0.9714\n",
            "Epoch 25/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.1286 - accuracy: 0.9645 - val_loss: 0.1145 - val_accuracy: 0.9714\n",
            "Epoch 26/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.1230 - accuracy: 0.9630 - val_loss: 0.1115 - val_accuracy: 0.9729\n",
            "Epoch 27/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.1237 - accuracy: 0.9675 - val_loss: 0.1079 - val_accuracy: 0.9743\n",
            "Epoch 28/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.1181 - accuracy: 0.9665 - val_loss: 0.1067 - val_accuracy: 0.9714\n",
            "Epoch 29/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.1170 - accuracy: 0.9685 - val_loss: 0.1105 - val_accuracy: 0.9657\n",
            "Epoch 30/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.1119 - accuracy: 0.9705 - val_loss: 0.1056 - val_accuracy: 0.9686\n",
            "Epoch 31/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.1073 - accuracy: 0.9690 - val_loss: 0.0961 - val_accuracy: 0.9800\n",
            "Epoch 32/250\n",
            "125/125 [==============================] - 5s 37ms/step - loss: 0.1069 - accuracy: 0.9700 - val_loss: 0.0936 - val_accuracy: 0.9814\n",
            "Epoch 33/250\n",
            "125/125 [==============================] - 5s 39ms/step - loss: 0.1055 - accuracy: 0.9695 - val_loss: 0.0923 - val_accuracy: 0.9800\n",
            "Epoch 34/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.1057 - accuracy: 0.9695 - val_loss: 0.0927 - val_accuracy: 0.9786\n",
            "Epoch 35/250\n",
            "125/125 [==============================] - 5s 37ms/step - loss: 0.1016 - accuracy: 0.9725 - val_loss: 0.0883 - val_accuracy: 0.9814\n",
            "Epoch 36/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.0987 - accuracy: 0.9700 - val_loss: 0.0898 - val_accuracy: 0.9771\n",
            "Epoch 37/250\n",
            "125/125 [==============================] - 5s 39ms/step - loss: 0.0962 - accuracy: 0.9730 - val_loss: 0.0879 - val_accuracy: 0.9771\n",
            "Epoch 38/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.0938 - accuracy: 0.9730 - val_loss: 0.0827 - val_accuracy: 0.9800\n",
            "Epoch 39/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.0928 - accuracy: 0.9745 - val_loss: 0.0814 - val_accuracy: 0.9814\n",
            "Epoch 40/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.0901 - accuracy: 0.9755 - val_loss: 0.0821 - val_accuracy: 0.9786\n",
            "Epoch 41/250\n",
            "125/125 [==============================] - 5s 37ms/step - loss: 0.0882 - accuracy: 0.9775 - val_loss: 0.0877 - val_accuracy: 0.9729\n",
            "Epoch 42/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.0896 - accuracy: 0.9745 - val_loss: 0.0783 - val_accuracy: 0.9800\n",
            "Epoch 43/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.0865 - accuracy: 0.9745 - val_loss: 0.0925 - val_accuracy: 0.9700\n",
            "Epoch 44/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.0885 - accuracy: 0.9750 - val_loss: 0.0860 - val_accuracy: 0.9743\n",
            "Epoch 45/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.0834 - accuracy: 0.9775 - val_loss: 0.0771 - val_accuracy: 0.9800\n",
            "Epoch 46/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.0879 - accuracy: 0.9750 - val_loss: 0.0735 - val_accuracy: 0.9814\n",
            "Epoch 47/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.0830 - accuracy: 0.9780 - val_loss: 0.0714 - val_accuracy: 0.9829\n",
            "Epoch 48/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.0832 - accuracy: 0.9745 - val_loss: 0.0707 - val_accuracy: 0.9829\n",
            "Epoch 49/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.0801 - accuracy: 0.9755 - val_loss: 0.0744 - val_accuracy: 0.9814\n",
            "Epoch 50/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.0807 - accuracy: 0.9775 - val_loss: 0.0693 - val_accuracy: 0.9814\n",
            "Epoch 51/250\n",
            "125/125 [==============================] - 5s 40ms/step - loss: 0.0761 - accuracy: 0.9790 - val_loss: 0.0667 - val_accuracy: 0.9814\n",
            "Epoch 52/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.0762 - accuracy: 0.9765 - val_loss: 0.0691 - val_accuracy: 0.9843\n",
            "Epoch 53/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.0742 - accuracy: 0.9765 - val_loss: 0.0651 - val_accuracy: 0.9829\n",
            "Epoch 54/250\n",
            "125/125 [==============================] - 5s 37ms/step - loss: 0.0727 - accuracy: 0.9785 - val_loss: 0.0741 - val_accuracy: 0.9800\n",
            "Epoch 55/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.0726 - accuracy: 0.9795 - val_loss: 0.0723 - val_accuracy: 0.9800\n",
            "Epoch 56/250\n",
            "125/125 [==============================] - 5s 41ms/step - loss: 0.0732 - accuracy: 0.9805 - val_loss: 0.0629 - val_accuracy: 0.9843\n",
            "Epoch 57/250\n",
            "125/125 [==============================] - 5s 40ms/step - loss: 0.0709 - accuracy: 0.9780 - val_loss: 0.0615 - val_accuracy: 0.9843\n",
            "Epoch 58/250\n",
            "125/125 [==============================] - 5s 37ms/step - loss: 0.0685 - accuracy: 0.9820 - val_loss: 0.0788 - val_accuracy: 0.9729\n",
            "Epoch 59/250\n",
            "125/125 [==============================] - 5s 38ms/step - loss: 0.0710 - accuracy: 0.9810 - val_loss: 0.0587 - val_accuracy: 0.9857\n",
            "Epoch 60/250\n",
            "125/125 [==============================] - 5s 38ms/step - loss: 0.0667 - accuracy: 0.9795 - val_loss: 0.0586 - val_accuracy: 0.9857\n",
            "Epoch 61/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.0682 - accuracy: 0.9810 - val_loss: 0.0581 - val_accuracy: 0.9843\n",
            "Epoch 62/250\n",
            "125/125 [==============================] - 5s 38ms/step - loss: 0.0678 - accuracy: 0.9840 - val_loss: 0.0562 - val_accuracy: 0.9857\n",
            "Epoch 63/250\n",
            "125/125 [==============================] - 5s 37ms/step - loss: 0.0669 - accuracy: 0.9790 - val_loss: 0.0586 - val_accuracy: 0.9829\n",
            "Epoch 64/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.0660 - accuracy: 0.9820 - val_loss: 0.0577 - val_accuracy: 0.9857\n",
            "Epoch 65/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.0639 - accuracy: 0.9830 - val_loss: 0.0540 - val_accuracy: 0.9871\n",
            "Epoch 66/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.0634 - accuracy: 0.9825 - val_loss: 0.0606 - val_accuracy: 0.9857\n",
            "Epoch 67/250\n",
            "125/125 [==============================] - 5s 37ms/step - loss: 0.0628 - accuracy: 0.9835 - val_loss: 0.0526 - val_accuracy: 0.9871\n",
            "Epoch 68/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.0632 - accuracy: 0.9825 - val_loss: 0.0531 - val_accuracy: 0.9886\n",
            "Epoch 69/250\n",
            "125/125 [==============================] - 5s 37ms/step - loss: 0.0624 - accuracy: 0.9835 - val_loss: 0.0567 - val_accuracy: 0.9857\n",
            "Epoch 70/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.0612 - accuracy: 0.9820 - val_loss: 0.0518 - val_accuracy: 0.9900\n",
            "Epoch 71/250\n",
            "125/125 [==============================] - 5s 37ms/step - loss: 0.0602 - accuracy: 0.9850 - val_loss: 0.0508 - val_accuracy: 0.9886\n",
            "Epoch 72/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.0600 - accuracy: 0.9830 - val_loss: 0.0572 - val_accuracy: 0.9843\n",
            "Epoch 73/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.0594 - accuracy: 0.9860 - val_loss: 0.0528 - val_accuracy: 0.9871\n",
            "Epoch 74/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.0579 - accuracy: 0.9840 - val_loss: 0.0486 - val_accuracy: 0.9900\n",
            "Epoch 75/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.0597 - accuracy: 0.9860 - val_loss: 0.0484 - val_accuracy: 0.9900\n",
            "Epoch 76/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.0580 - accuracy: 0.9850 - val_loss: 0.0470 - val_accuracy: 0.9914\n",
            "Epoch 77/250\n",
            "125/125 [==============================] - 5s 37ms/step - loss: 0.0585 - accuracy: 0.9835 - val_loss: 0.0468 - val_accuracy: 0.9900\n",
            "Epoch 78/250\n",
            "125/125 [==============================] - 5s 38ms/step - loss: 0.0558 - accuracy: 0.9850 - val_loss: 0.0489 - val_accuracy: 0.9871\n",
            "Epoch 79/250\n",
            "125/125 [==============================] - 5s 39ms/step - loss: 0.0556 - accuracy: 0.9845 - val_loss: 0.0472 - val_accuracy: 0.9886\n",
            "Epoch 80/250\n",
            "125/125 [==============================] - 5s 37ms/step - loss: 0.0551 - accuracy: 0.9805 - val_loss: 0.0442 - val_accuracy: 0.9900\n",
            "Epoch 81/250\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.0547 - accuracy: 0.9850 - val_loss: 0.0504 - val_accuracy: 0.9829\n",
            "Epoch 82/250\n",
            "125/125 [==============================] - 5s 37ms/step - loss: 0.0537 - accuracy: 0.9850 - val_loss: 0.0396 - val_accuracy: 0.9914\n",
            "Epoch 83/250\n",
            "125/125 [==============================] - 5s 41ms/step - loss: 0.0540 - accuracy: 0.9840 - val_loss: 0.0446 - val_accuracy: 0.9900\n",
            "Epoch 84/250\n",
            "125/125 [==============================] - 6s 44ms/step - loss: 0.0524 - accuracy: 0.9865 - val_loss: 0.0388 - val_accuracy: 0.9914\n",
            "Epoch 85/250\n",
            "125/125 [==============================] - 6s 46ms/step - loss: 0.0509 - accuracy: 0.9850 - val_loss: 0.0372 - val_accuracy: 0.9929\n",
            "Epoch 86/250\n",
            "125/125 [==============================] - 5s 44ms/step - loss: 0.0511 - accuracy: 0.9835 - val_loss: 0.0387 - val_accuracy: 0.9914\n",
            "Epoch 87/250\n",
            "125/125 [==============================] - 5s 39ms/step - loss: 0.0520 - accuracy: 0.9870 - val_loss: 0.0447 - val_accuracy: 0.9871\n",
            "Epoch 88/250\n",
            "125/125 [==============================] - 5s 39ms/step - loss: 0.0508 - accuracy: 0.9870 - val_loss: 0.0400 - val_accuracy: 0.9900\n",
            "Epoch 89/250\n",
            "125/125 [==============================] - 5s 41ms/step - loss: 0.0505 - accuracy: 0.9870 - val_loss: 0.0395 - val_accuracy: 0.9900\n",
            "Epoch 90/250\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0488 - accuracy: 0.9875 - val_loss: 0.0350 - val_accuracy: 0.9929\n",
            "Epoch 91/250\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0494 - accuracy: 0.9865 - val_loss: 0.0345 - val_accuracy: 0.9929\n",
            "Epoch 92/250\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0483 - accuracy: 0.9865 - val_loss: 0.0355 - val_accuracy: 0.9914\n",
            "Epoch 93/250\n",
            "125/125 [==============================] - 5s 39ms/step - loss: 0.0487 - accuracy: 0.9860 - val_loss: 0.0398 - val_accuracy: 0.9900\n",
            "Epoch 94/250\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0484 - accuracy: 0.9855 - val_loss: 0.0335 - val_accuracy: 0.9929\n",
            "Epoch 95/250\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0505 - accuracy: 0.9850 - val_loss: 0.0515 - val_accuracy: 0.9814\n",
            "Epoch 96/250\n",
            "125/125 [==============================] - 5s 37ms/step - loss: 0.0481 - accuracy: 0.9835 - val_loss: 0.0346 - val_accuracy: 0.9914\n",
            "Epoch 97/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0468 - accuracy: 0.9850 - val_loss: 0.0338 - val_accuracy: 0.9929\n",
            "Epoch 98/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0468 - accuracy: 0.9860 - val_loss: 0.0390 - val_accuracy: 0.9886\n",
            "Epoch 99/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0465 - accuracy: 0.9870 - val_loss: 0.0347 - val_accuracy: 0.9900\n",
            "Epoch 100/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0467 - accuracy: 0.9860 - val_loss: 0.0337 - val_accuracy: 0.9929\n",
            "Epoch 101/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0453 - accuracy: 0.9880 - val_loss: 0.0367 - val_accuracy: 0.9900\n",
            "Epoch 102/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0447 - accuracy: 0.9870 - val_loss: 0.0328 - val_accuracy: 0.9929\n",
            "Epoch 103/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0434 - accuracy: 0.9860 - val_loss: 0.0330 - val_accuracy: 0.9914\n",
            "Epoch 104/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0425 - accuracy: 0.9885 - val_loss: 0.0386 - val_accuracy: 0.9871\n",
            "Epoch 105/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0434 - accuracy: 0.9875 - val_loss: 0.0317 - val_accuracy: 0.9929\n",
            "Epoch 106/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0431 - accuracy: 0.9870 - val_loss: 0.0350 - val_accuracy: 0.9900\n",
            "Epoch 107/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0430 - accuracy: 0.9855 - val_loss: 0.0323 - val_accuracy: 0.9929\n",
            "Epoch 108/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0430 - accuracy: 0.9870 - val_loss: 0.0324 - val_accuracy: 0.9914\n",
            "Epoch 109/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0428 - accuracy: 0.9855 - val_loss: 0.0325 - val_accuracy: 0.9900\n",
            "Epoch 110/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0423 - accuracy: 0.9865 - val_loss: 0.0307 - val_accuracy: 0.9929\n",
            "Epoch 111/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0413 - accuracy: 0.9860 - val_loss: 0.0369 - val_accuracy: 0.9871\n",
            "Epoch 112/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0423 - accuracy: 0.9850 - val_loss: 0.0335 - val_accuracy: 0.9900\n",
            "Epoch 113/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0415 - accuracy: 0.9870 - val_loss: 0.0305 - val_accuracy: 0.9929\n",
            "Epoch 114/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0415 - accuracy: 0.9870 - val_loss: 0.0360 - val_accuracy: 0.9871\n",
            "Epoch 115/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0409 - accuracy: 0.9890 - val_loss: 0.0308 - val_accuracy: 0.9900\n",
            "Epoch 116/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0419 - accuracy: 0.9860 - val_loss: 0.0294 - val_accuracy: 0.9929\n",
            "Epoch 117/250\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.0403 - accuracy: 0.9875 - val_loss: 0.0392 - val_accuracy: 0.9871\n",
            "Epoch 118/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0417 - accuracy: 0.9865 - val_loss: 0.0318 - val_accuracy: 0.9900\n",
            "Epoch 119/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0408 - accuracy: 0.9890 - val_loss: 0.0308 - val_accuracy: 0.9900\n",
            "Epoch 120/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0400 - accuracy: 0.9880 - val_loss: 0.0361 - val_accuracy: 0.9871\n",
            "Epoch 121/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0407 - accuracy: 0.9875 - val_loss: 0.0306 - val_accuracy: 0.9900\n",
            "Epoch 122/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0404 - accuracy: 0.9855 - val_loss: 0.0305 - val_accuracy: 0.9900\n",
            "Epoch 123/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0407 - accuracy: 0.9875 - val_loss: 0.0297 - val_accuracy: 0.9929\n",
            "Epoch 124/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0401 - accuracy: 0.9865 - val_loss: 0.0293 - val_accuracy: 0.9914\n",
            "Epoch 125/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0422 - accuracy: 0.9875 - val_loss: 0.0313 - val_accuracy: 0.9886\n",
            "Epoch 126/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0402 - accuracy: 0.9865 - val_loss: 0.0270 - val_accuracy: 0.9914\n",
            "Epoch 127/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0379 - accuracy: 0.9885 - val_loss: 0.0320 - val_accuracy: 0.9871\n",
            "Epoch 128/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0404 - accuracy: 0.9860 - val_loss: 0.0271 - val_accuracy: 0.9900\n",
            "Epoch 129/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0385 - accuracy: 0.9855 - val_loss: 0.0290 - val_accuracy: 0.9871\n",
            "Epoch 130/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0374 - accuracy: 0.9885 - val_loss: 0.0232 - val_accuracy: 0.9929\n",
            "Epoch 131/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0367 - accuracy: 0.9885 - val_loss: 0.0281 - val_accuracy: 0.9886\n",
            "Epoch 132/250\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.0370 - accuracy: 0.9900 - val_loss: 0.0211 - val_accuracy: 0.9929\n",
            "Epoch 133/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0358 - accuracy: 0.9880 - val_loss: 0.0233 - val_accuracy: 0.9900\n",
            "Epoch 134/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0360 - accuracy: 0.9885 - val_loss: 0.0212 - val_accuracy: 0.9914\n",
            "Epoch 135/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0359 - accuracy: 0.9880 - val_loss: 0.0228 - val_accuracy: 0.9914\n",
            "Epoch 136/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0355 - accuracy: 0.9880 - val_loss: 0.0227 - val_accuracy: 0.9914\n",
            "Epoch 137/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0371 - accuracy: 0.9880 - val_loss: 0.0219 - val_accuracy: 0.9914\n",
            "Epoch 138/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0352 - accuracy: 0.9875 - val_loss: 0.0212 - val_accuracy: 0.9914\n",
            "Epoch 139/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0375 - accuracy: 0.9880 - val_loss: 0.0235 - val_accuracy: 0.9914\n",
            "Epoch 140/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0351 - accuracy: 0.9870 - val_loss: 0.0229 - val_accuracy: 0.9900\n",
            "Epoch 141/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0340 - accuracy: 0.9900 - val_loss: 0.0192 - val_accuracy: 0.9943\n",
            "Epoch 142/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0356 - accuracy: 0.9865 - val_loss: 0.0191 - val_accuracy: 0.9943\n",
            "Epoch 143/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0352 - accuracy: 0.9880 - val_loss: 0.0196 - val_accuracy: 0.9943\n",
            "Epoch 144/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0350 - accuracy: 0.9885 - val_loss: 0.0203 - val_accuracy: 0.9914\n",
            "Epoch 145/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0348 - accuracy: 0.9885 - val_loss: 0.0192 - val_accuracy: 0.9929\n",
            "Epoch 146/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0359 - accuracy: 0.9880 - val_loss: 0.0210 - val_accuracy: 0.9914\n",
            "Epoch 147/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0343 - accuracy: 0.9885 - val_loss: 0.0193 - val_accuracy: 0.9943\n",
            "Epoch 148/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0343 - accuracy: 0.9860 - val_loss: 0.0189 - val_accuracy: 0.9943\n",
            "Epoch 149/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0342 - accuracy: 0.9875 - val_loss: 0.0185 - val_accuracy: 0.9943\n",
            "Epoch 150/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0343 - accuracy: 0.9875 - val_loss: 0.0209 - val_accuracy: 0.9914\n",
            "Epoch 151/250\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.0340 - accuracy: 0.9875 - val_loss: 0.0190 - val_accuracy: 0.9914\n",
            "Epoch 152/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0339 - accuracy: 0.9905 - val_loss: 0.0185 - val_accuracy: 0.9943\n",
            "Epoch 153/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0339 - accuracy: 0.9885 - val_loss: 0.0188 - val_accuracy: 0.9929\n",
            "Epoch 154/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0333 - accuracy: 0.9880 - val_loss: 0.0253 - val_accuracy: 0.9886\n",
            "Epoch 155/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0339 - accuracy: 0.9885 - val_loss: 0.0214 - val_accuracy: 0.9900\n",
            "Epoch 156/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0336 - accuracy: 0.9885 - val_loss: 0.0201 - val_accuracy: 0.9900\n",
            "Epoch 157/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0339 - accuracy: 0.9885 - val_loss: 0.0210 - val_accuracy: 0.9900\n",
            "Epoch 158/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0328 - accuracy: 0.9880 - val_loss: 0.0234 - val_accuracy: 0.9886\n",
            "Epoch 159/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0326 - accuracy: 0.9885 - val_loss: 0.0178 - val_accuracy: 0.9943\n",
            "Epoch 160/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0332 - accuracy: 0.9880 - val_loss: 0.0176 - val_accuracy: 0.9943\n",
            "Epoch 161/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0332 - accuracy: 0.9880 - val_loss: 0.0188 - val_accuracy: 0.9900\n",
            "Epoch 162/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0327 - accuracy: 0.9870 - val_loss: 0.0192 - val_accuracy: 0.9900\n",
            "Epoch 163/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0328 - accuracy: 0.9890 - val_loss: 0.0168 - val_accuracy: 0.9943\n",
            "Epoch 164/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0326 - accuracy: 0.9875 - val_loss: 0.0215 - val_accuracy: 0.9886\n",
            "Epoch 165/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0319 - accuracy: 0.9890 - val_loss: 0.0166 - val_accuracy: 0.9943\n",
            "Epoch 166/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0326 - accuracy: 0.9875 - val_loss: 0.0203 - val_accuracy: 0.9900\n",
            "Epoch 167/250\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.0332 - accuracy: 0.9885 - val_loss: 0.0166 - val_accuracy: 0.9943\n",
            "Epoch 168/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0334 - accuracy: 0.9880 - val_loss: 0.0184 - val_accuracy: 0.9900\n",
            "Epoch 169/250\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.0321 - accuracy: 0.9880 - val_loss: 0.0228 - val_accuracy: 0.9886\n",
            "Epoch 170/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0327 - accuracy: 0.9890 - val_loss: 0.0186 - val_accuracy: 0.9900\n",
            "Epoch 171/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0325 - accuracy: 0.9890 - val_loss: 0.0199 - val_accuracy: 0.9900\n",
            "Epoch 172/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0327 - accuracy: 0.9875 - val_loss: 0.0173 - val_accuracy: 0.9943\n",
            "Epoch 173/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0321 - accuracy: 0.9885 - val_loss: 0.0197 - val_accuracy: 0.9886\n",
            "Epoch 174/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0316 - accuracy: 0.9875 - val_loss: 0.0180 - val_accuracy: 0.9900\n",
            "Epoch 175/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0316 - accuracy: 0.9875 - val_loss: 0.0226 - val_accuracy: 0.9886\n",
            "Epoch 176/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0319 - accuracy: 0.9890 - val_loss: 0.0168 - val_accuracy: 0.9914\n",
            "Epoch 177/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0321 - accuracy: 0.9890 - val_loss: 0.0169 - val_accuracy: 0.9900\n",
            "Epoch 178/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0323 - accuracy: 0.9900 - val_loss: 0.0171 - val_accuracy: 0.9900\n",
            "Epoch 179/250\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.0322 - accuracy: 0.9880 - val_loss: 0.0170 - val_accuracy: 0.9900\n",
            "Epoch 180/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0322 - accuracy: 0.9875 - val_loss: 0.0209 - val_accuracy: 0.9900\n",
            "Epoch 181/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0315 - accuracy: 0.9885 - val_loss: 0.0206 - val_accuracy: 0.9886\n",
            "Epoch 182/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0326 - accuracy: 0.9880 - val_loss: 0.0149 - val_accuracy: 0.9957\n",
            "Epoch 183/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0314 - accuracy: 0.9905 - val_loss: 0.0186 - val_accuracy: 0.9900\n",
            "Epoch 184/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0320 - accuracy: 0.9890 - val_loss: 0.0204 - val_accuracy: 0.9886\n",
            "Epoch 185/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0313 - accuracy: 0.9895 - val_loss: 0.0175 - val_accuracy: 0.9900\n",
            "Epoch 186/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0313 - accuracy: 0.9895 - val_loss: 0.0155 - val_accuracy: 0.9957\n",
            "Epoch 187/250\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.0315 - accuracy: 0.9880 - val_loss: 0.0174 - val_accuracy: 0.9900\n",
            "Epoch 188/250\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.0316 - accuracy: 0.9885 - val_loss: 0.0200 - val_accuracy: 0.9886\n",
            "Epoch 189/250\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.0317 - accuracy: 0.9880 - val_loss: 0.0220 - val_accuracy: 0.9886\n",
            "Epoch 190/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0315 - accuracy: 0.9885 - val_loss: 0.0212 - val_accuracy: 0.9886\n",
            "Epoch 191/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0312 - accuracy: 0.9895 - val_loss: 0.0169 - val_accuracy: 0.9914\n",
            "Epoch 192/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0307 - accuracy: 0.9890 - val_loss: 0.0178 - val_accuracy: 0.9900\n",
            "Epoch 193/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0310 - accuracy: 0.9900 - val_loss: 0.0156 - val_accuracy: 0.9943\n",
            "Epoch 194/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0310 - accuracy: 0.9895 - val_loss: 0.0193 - val_accuracy: 0.9886\n",
            "Epoch 195/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0316 - accuracy: 0.9905 - val_loss: 0.0183 - val_accuracy: 0.9886\n",
            "Epoch 196/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0308 - accuracy: 0.9890 - val_loss: 0.0196 - val_accuracy: 0.9886\n",
            "Epoch 197/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0313 - accuracy: 0.9895 - val_loss: 0.0170 - val_accuracy: 0.9914\n",
            "Epoch 198/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0307 - accuracy: 0.9890 - val_loss: 0.0162 - val_accuracy: 0.9914\n",
            "Epoch 199/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0295 - accuracy: 0.9890 - val_loss: 0.0184 - val_accuracy: 0.9900\n",
            "Epoch 200/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0291 - accuracy: 0.9890 - val_loss: 0.0203 - val_accuracy: 0.9886\n",
            "Epoch 201/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0286 - accuracy: 0.9910 - val_loss: 0.0180 - val_accuracy: 0.9900\n",
            "Epoch 202/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0292 - accuracy: 0.9890 - val_loss: 0.0197 - val_accuracy: 0.9900\n",
            "Epoch 203/250\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.0298 - accuracy: 0.9880 - val_loss: 0.0173 - val_accuracy: 0.9914\n",
            "Epoch 204/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0291 - accuracy: 0.9895 - val_loss: 0.0155 - val_accuracy: 0.9929\n",
            "Epoch 205/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0279 - accuracy: 0.9900 - val_loss: 0.0160 - val_accuracy: 0.9914\n",
            "Epoch 206/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0279 - accuracy: 0.9890 - val_loss: 0.0180 - val_accuracy: 0.9900\n",
            "Epoch 207/250\n",
            "125/125 [==============================] - 4s 31ms/step - loss: 0.0280 - accuracy: 0.9900 - val_loss: 0.0173 - val_accuracy: 0.9914\n",
            "Epoch 208/250\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.0285 - accuracy: 0.9910 - val_loss: 0.0170 - val_accuracy: 0.9900\n",
            "Epoch 209/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0281 - accuracy: 0.9895 - val_loss: 0.0179 - val_accuracy: 0.9900\n",
            "Epoch 210/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0275 - accuracy: 0.9900 - val_loss: 0.0133 - val_accuracy: 0.9957\n",
            "Epoch 211/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0282 - accuracy: 0.9895 - val_loss: 0.0161 - val_accuracy: 0.9929\n",
            "Epoch 212/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0276 - accuracy: 0.9915 - val_loss: 0.0139 - val_accuracy: 0.9957\n",
            "Epoch 213/250\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.0283 - accuracy: 0.9905 - val_loss: 0.0145 - val_accuracy: 0.9943\n",
            "Epoch 214/250\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0285 - accuracy: 0.9890 - val_loss: 0.0207 - val_accuracy: 0.9900\n",
            "Epoch 215/250\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0281 - accuracy: 0.9895 - val_loss: 0.0160 - val_accuracy: 0.9914\n",
            "Epoch 216/250\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0276 - accuracy: 0.9905 - val_loss: 0.0138 - val_accuracy: 0.9957\n",
            "Epoch 217/250\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0278 - accuracy: 0.9910 - val_loss: 0.0178 - val_accuracy: 0.9914\n",
            "Epoch 218/250\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0279 - accuracy: 0.9910 - val_loss: 0.0194 - val_accuracy: 0.9900\n",
            "Epoch 219/250\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0279 - accuracy: 0.9890 - val_loss: 0.0208 - val_accuracy: 0.9900\n",
            "Epoch 220/250\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0280 - accuracy: 0.9910 - val_loss: 0.0190 - val_accuracy: 0.9900\n",
            "Epoch 221/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.0278 - accuracy: 0.9895 - val_loss: 0.0159 - val_accuracy: 0.9914\n",
            "Epoch 222/250\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0283 - accuracy: 0.9895 - val_loss: 0.0156 - val_accuracy: 0.9914\n",
            "Epoch 223/250\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.0276 - accuracy: 0.9905 - val_loss: 0.0169 - val_accuracy: 0.9914\n",
            "Epoch 224/250\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0281 - accuracy: 0.9905 - val_loss: 0.0149 - val_accuracy: 0.9943\n",
            "Epoch 225/250\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0274 - accuracy: 0.9905 - val_loss: 0.0151 - val_accuracy: 0.9929\n",
            "Epoch 226/250\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0276 - accuracy: 0.9890 - val_loss: 0.0162 - val_accuracy: 0.9914\n",
            "Epoch 227/250\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0276 - accuracy: 0.9895 - val_loss: 0.0168 - val_accuracy: 0.9900\n",
            "Epoch 228/250\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0283 - accuracy: 0.9900 - val_loss: 0.0153 - val_accuracy: 0.9914\n",
            "Epoch 229/250\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0278 - accuracy: 0.9885 - val_loss: 0.0157 - val_accuracy: 0.9900\n",
            "Epoch 230/250\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0279 - accuracy: 0.9905 - val_loss: 0.0139 - val_accuracy: 0.9943\n",
            "Epoch 231/250\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0288 - accuracy: 0.9890 - val_loss: 0.0144 - val_accuracy: 0.9943\n",
            "Epoch 232/250\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0274 - accuracy: 0.9900 - val_loss: 0.0165 - val_accuracy: 0.9914\n",
            "Epoch 233/250\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0274 - accuracy: 0.9910 - val_loss: 0.0160 - val_accuracy: 0.9914\n",
            "Epoch 234/250\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0275 - accuracy: 0.9895 - val_loss: 0.0189 - val_accuracy: 0.9900\n",
            "Epoch 235/250\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0285 - accuracy: 0.9895 - val_loss: 0.0165 - val_accuracy: 0.9914\n",
            "Epoch 236/250\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0283 - accuracy: 0.9890 - val_loss: 0.0139 - val_accuracy: 0.9943\n",
            "Epoch 237/250\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0273 - accuracy: 0.9890 - val_loss: 0.0182 - val_accuracy: 0.9900\n",
            "Epoch 238/250\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0272 - accuracy: 0.9910 - val_loss: 0.0148 - val_accuracy: 0.9943\n",
            "Epoch 239/250\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0274 - accuracy: 0.9900 - val_loss: 0.0152 - val_accuracy: 0.9929\n",
            "Epoch 240/250\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.0265 - accuracy: 0.9910 - val_loss: 0.0126 - val_accuracy: 0.9957\n",
            "Epoch 241/250\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0286 - accuracy: 0.9890 - val_loss: 0.0160 - val_accuracy: 0.9900\n",
            "Epoch 242/250\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0280 - accuracy: 0.9900 - val_loss: 0.0159 - val_accuracy: 0.9929\n",
            "Epoch 243/250\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0272 - accuracy: 0.9890 - val_loss: 0.0147 - val_accuracy: 0.9943\n",
            "Epoch 244/250\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0273 - accuracy: 0.9910 - val_loss: 0.0163 - val_accuracy: 0.9900\n",
            "Epoch 245/250\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0272 - accuracy: 0.9900 - val_loss: 0.0164 - val_accuracy: 0.9914\n",
            "Epoch 246/250\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0274 - accuracy: 0.9895 - val_loss: 0.0145 - val_accuracy: 0.9943\n",
            "Epoch 247/250\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0276 - accuracy: 0.9880 - val_loss: 0.0151 - val_accuracy: 0.9914\n",
            "Epoch 248/250\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0273 - accuracy: 0.9905 - val_loss: 0.0148 - val_accuracy: 0.9929\n",
            "Epoch 249/250\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0270 - accuracy: 0.9900 - val_loss: 0.0152 - val_accuracy: 0.9914\n",
            "Epoch 250/250\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0270 - accuracy: 0.9905 - val_loss: 0.0164 - val_accuracy: 0.9914\n"
          ]
        }
      ],
      "source": [
        "history: list = model.fit(\n",
        "    train_padded,\n",
        "    train_label,\n",
        "    batch_size=16,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=(validation_padded, validation_label),\n",
        ").history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 470,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save(str(f\".\\models\\model_{num_epochs}e.h5\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 471,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model(str(f\".\\models\\model_{num_epochs}e.h5\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 472,
      "metadata": {
        "id": "lqdfFJ0LvLWL"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "execution_count": 472,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs=range(len(history['accuracy']))\n",
        "\n",
        "acc = history['accuracy']\n",
        "val_acc = history['val_accuracy']\n",
        "plt.plot(epochs, acc, 'g', 'Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'r', 'Validation Accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.figure()\n",
        "\n",
        "loss = history['loss']\n",
        "val_loss = history['val_loss']\n",
        "plt.plot(epochs, loss, 'g', 'Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r', 'Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.figure()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generate From Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 473,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 18s 6ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[1.   ],\n",
              "       [1.   ],\n",
              "       [1.   ],\n",
              "       ...,\n",
              "       [0.002],\n",
              "       [1.   ],\n",
              "       [0.002]], dtype=float32)"
            ]
          },
          "execution_count": 473,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions: numpy.array = model.predict(predict_padded, batch_size=16, verbose=1)\n",
        "numpy.round(predictions, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Classify the predictions into 'Pro or 'Con"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 474,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1.         1.         1.         1.         0.00118515 0.00130841]]\n",
            "['Pro' 'Pro' 'Pro' 'Pro' 'Con' 'Con']\n"
          ]
        }
      ],
      "source": [
        "classifications = []\n",
        "for value in predictions:\n",
        "    if (value > 0.5): classifications.append(\"Pro\")\n",
        "    else: classifications.append(\"Con\")\n",
        "classifications = numpy.asarray(classifications)\n",
        "\n",
        "print(predictions[:6].T)\n",
        "print(classifications[:6].T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save Predictions to File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 475,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(str(f\".\\predictions\\predictions_{num_epochs}e.csv\"), 'w') as output:\n",
        "    for index in range(len(predict_text)):\n",
        "        output.write(f\"\\\"{predict_text[index]}\\\",{classifications[index]}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Compare Predictions Against Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Against Prediction Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 476,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The screen is not easy to read in direct sunlight.\n",
            " => Con\n",
            "Cheap!, Color Screen, Battery Life, polyphonic ring tones\n",
            " => Pro\n",
            "16MB memory stick is a little bit small \n",
            " => Con\n",
            "Small, lightweight\n",
            " => Pro\n",
            "Nokia 8310\n",
            " => Pro\n",
            "Cheap, some useful features, phone wraps, good sound quality\n",
            " => Pro\n",
            "Intended functionality.\n",
            " => Pro\n",
            "2.1 mega pixel\n",
            " => Con\n"
          ]
        }
      ],
      "source": [
        "for index in random.sample(range(len(predict_text)), 8):\n",
        "    print(predict_text[index])\n",
        "    print(f\" => {classifications[index]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Against Ambiguous Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 477,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/12 [==============================] - 1s 8ms/step\n",
            "\"Not great, but if you are working on a budget, you can do worse\" |= PRO\n",
            " => Pro\n",
            "\"Absolutely the worst!\" |= CON\n",
            " => Pro\n",
            "\"Broken upon arrival\" |= CON\n",
            " => Pro\n",
            "\"I want to love this, but I can't really recommend\" |= CON\n",
            " => Pro\n",
            "\"Crap product, terrible design, cheap\" |= CON\n",
            " => Con\n",
            "\"Pickup when on sale, not worth full price\" |= CON\n",
            " => Con\n",
            "\"Great for amateurs\" |= PRO\n",
            " => Pro\n",
            "\"Recommend only to professionals\" |= CON\n",
            " => Pro\n",
            "\"fantastic for dumpsters\" |= CON\n",
            " => Pro\n",
            "\"Recommend if you have no idea what you are doing\" =| PRO\n",
            " => Pro\n",
            "\"goes right in the dumpster\" |= CON\n",
            " => Con\n",
            "\"best to avoid this\" |= CON\n",
            " => Pro\n"
          ]
        }
      ],
      "source": [
        "user_text = [\n",
        "    \"\\\"Not great, but if you are working on a budget, you can do worse\\\" |= PRO\",\n",
        "    \"\\\"Absolutely the worst!\\\" |= CON\",\n",
        "    \"\\\"Broken upon arrival\\\" |= CON\",\n",
        "    \"\\\"I want to love this, but I can't really recommend\\\" |= CON\",\n",
        "    \"\\\"Crap product, terrible design, cheap\\\" |= CON\",\n",
        "    \"\\\"Pickup when on sale, not worth full price\\\" |= CON\",\n",
        "    \"\\\"Great for amateurs\\\" |= PRO\",\n",
        "    \"\\\"Recommend only to professionals\\\" |= CON\",\n",
        "    \"\\\"fantastic for dumpsters\\\" |= CON\",\n",
        "    \"\\\"Recommend if you have no idea what you are doing\\\" =| PRO\",\n",
        "    \"\\\"goes right in the dumpster\\\" |= CON\",\n",
        "    \"\\\"best to avoid this\\\" |= CON\",\n",
        "    # \"\\\"replace\\\"\",\n",
        "]\n",
        "\n",
        "user_sequences = tokenizer.texts_to_sequences(user_text)\n",
        "user_padded = tfpp.sequence.pad_sequences(user_sequences, maxlen=sequence_length)\n",
        "\n",
        "user_predictions = model.predict(user_padded, batch_size=1, verbose=1)\n",
        "\n",
        "user_classifications = []\n",
        "for value in predictions:\n",
        "    if (value > 0.5): user_classifications.append(\"Pro\")\n",
        "    else: user_classifications.append(\"Con\")\n",
        "user_classifications = numpy.asarray(classifications)\n",
        "\n",
        "for index in range(len(user_text)):\n",
        "    print(user_text[index])\n",
        "    print(f\" => {user_classifications[index]}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "rsPWakpbkXBn",
        "bh36uIRSkapY",
        "URj_ywt5kdsQ",
        "fNAERD45tC1m"
      ],
      "name": "pros_cons.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
